{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31d73283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/17 19:45:48 WARN Utils: Your hostname, Sujeets-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.29.122 instead (on interface en0)\n",
      "23/02/17 19:45:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/17 19:45:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/02/17 19:45:50 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/02/17 19:45:50 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "23/02/17 19:45:50 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "23/02/17 19:45:50 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "23/02/17 19:45:50 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "23/02/17 19:45:50 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "23/02/17 19:45:50 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n",
      "23/02/17 19:45:50 WARN Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('practise29').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c97da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [ (1, 'maheer', 2000, 2) , (2, 'wafa', 3000, 1) , (3, 'abcd', 1000, 4)]\n",
    "schema1 = ['id', 'name', 'salary', 'dep']\n",
    "data2 = [(1, 'IT'), (2, 'HR'), (3, 'Payroll')]\n",
    "schema2 = ['id', 'name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63209040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+\n",
      "| id|  name|salary|dep|\n",
      "+---+------+------+---+\n",
      "|  1|maheer|  2000|  2|\n",
      "|  2|  wafa|  3000|  1|\n",
      "|  3|  abcd|  1000|  4|\n",
      "+---+------+------+---+\n",
      "\n",
      "+---+-------+\n",
      "| id|   name|\n",
      "+---+-------+\n",
      "|  1|     IT|\n",
      "|  2|     HR|\n",
      "|  3|Payroll|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf = spark.createDataFrame (data1, schema1)\n",
    "depDf = spark.createDataFrame (data2,schema2)\n",
    "empDf.show ()\n",
    "depDf.show ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16c2f7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+---+----+\n",
      "| id|  name|salary|dep| id|name|\n",
      "+---+------+------+---+---+----+\n",
      "|  2|  wafa|  3000|  1|  1|  IT|\n",
      "|  1|maheer|  2000|  2|  2|  HR|\n",
      "+---+------+------+---+---+----+\n",
      "\n",
      "+---+------+------+---+----+----+\n",
      "| id|  name|salary|dep|  id|name|\n",
      "+---+------+------+---+----+----+\n",
      "|  1|maheer|  2000|  2|   2|  HR|\n",
      "|  2|  wafa|  3000|  1|   1|  IT|\n",
      "|  3|  abcd|  1000|  4|null|null|\n",
      "+---+------+------+---+----+----+\n",
      "\n",
      "+----+------+------+----+---+-------+\n",
      "|  id|  name|salary| dep| id|   name|\n",
      "+----+------+------+----+---+-------+\n",
      "|   2|  wafa|  3000|   1|  1|     IT|\n",
      "|   1|maheer|  2000|   2|  2|     HR|\n",
      "|null|  null|  null|null|  3|Payroll|\n",
      "+----+------+------+----+---+-------+\n",
      "\n",
      "+----+------+------+----+----+-------+\n",
      "|  id|  name|salary| dep|  id|   name|\n",
      "+----+------+------+----+----+-------+\n",
      "|   2|  wafa|  3000|   1|   1|     IT|\n",
      "|   1|maheer|  2000|   2|   2|     HR|\n",
      "|null|  null|  null|null|   3|Payroll|\n",
      "|   3|  abcd|  1000|   4|null|   null|\n",
      "+----+------+------+----+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDf.join (depDf, empDf.dep==depDf.id, 'inner').show () \n",
    "empDf.join (depDf, empDf.dep==depDf.id, 'left').show () \n",
    "empDf.join (depDf, empDf.dep==depDf.id, 'right').show () \n",
    "empDf.join (depDf, empDf.dep==depDf.id, 'full').show ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b483a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
